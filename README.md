# ğŸ“Š Projeto de Pipeline de CotaÃ§Ãµes Cambiais  

Este projeto implementa um **pipeline de dados** para consultar, transformar, armazenar e visualizar informaÃ§Ãµes de cotaÃ§Ãµes de moedas.  
A ideia central Ã© simular um processo de **ELT (Extract, Load, Transform)** em um fluxo simples, mas com boas prÃ¡ticas de organizaÃ§Ã£o.

---

## ğŸ”‘ Principais Etapas do Projeto  

### 1. **ExtraÃ§Ã£o de Dados (API)**
- O mÃ³dulo [`api.py`](./api.py) consulta a API [Open Exchange Rates](https://open.er-api.com/v6/latest/BRL) (ou similar) para obter as taxas de cÃ¢mbio.  
- Caso a API esteja indisponÃ­vel, hÃ¡ tratamento de erros para evitar falhas no processo.  

### 2. **TransformaÃ§Ã£o**
- O mÃ³dulo [`transformacao.py`](./transformacao.py) organiza os dados extraÃ­dos.  
- As informaÃ§Ãµes sÃ£o convertidas em um **DataFrame do pandas**, contendo:
  - Data da atualizaÃ§Ã£o  
  - Moeda  
  - CotaÃ§Ã£o em relaÃ§Ã£o ao **BRL**  
- A data vinda da API Ã© padronizada para facilitar anÃ¡lises posteriores.

### 3. **Armazenamento no Data Lake**
- Em [`data_lake.py`](./data_lake.py), os dados transformados sÃ£o salvos em **formato Parquet**, dentro da pasta `data_lake/`.  
- O nome do arquivo inclui a data da atualizaÃ§Ã£o, facilitando versionamento e histÃ³rico.  
- Esse formato foi escolhido por ser compacto e eficiente para consultas.

### 4. **Curadoria e OrganizaÃ§Ã£o**
- O mÃ³dulo [`organizacao.py`](./organizacao.py) processa os dados salvos e gera arquivos derivados, como:
  - `media.csv` â†’ contendo a mÃ©dia das cotaÃ§Ãµes.  
- Essa camada representa a Ã¡rea **curated** do Data Lake (`data_lake/curated`).

### 5. **VisualizaÃ§Ã£o**
- O mÃ³dulo [`visu.py`](./visu.py) gera **grÃ¡ficos simulados** de evoluÃ§Ã£o das moedas ao longo de 10 anos.  
- As visualizaÃ§Ãµes sÃ£o salvas automaticamente em `graficos_output/`.  
- Foram utilizadas as bibliotecas **Matplotlib** e **Seaborn** para criar grÃ¡ficos claros e bem formatados.

### 6. **OrquestraÃ§Ã£o**
- O arquivo principal [`main.py`](./main.py) integra todas as etapas:
  1. Extrai os dados da API  
  2. Transforma em DataFrame  
  3. Salva no Data Lake  
  4. Executa a curadoria  
  5. Gera as visualizaÃ§Ãµes  

---

## ğŸš€ Como Executar  

1. Clone este repositÃ³rio:  
   ```bash
   git clone https://github.com/seu-usuario/projeto-cambio.git
   cd projeto-cambio
   ```

2. Instale as dependÃªncias:  
   ```bash
   pip install -r requirements.txt
   ```

3. Execute o pipeline:  
   ```bash
   python main.py
   ```

---

## ğŸ“‚ Estrutura de Pastas  

```
projeto-cambio/
â”‚â”€â”€ api.py              # ExtraÃ§Ã£o de dados da API
â”‚â”€â”€ transformacao.py    # TransformaÃ§Ã£o dos dados em DataFrame
â”‚â”€â”€ data_lake.py        # Salvamento em Parquet
â”‚â”€â”€ organizacao.py      # Curadoria dos dados
â”‚â”€â”€ visu.py             # VisualizaÃ§Ã£o (grÃ¡ficos)
â”‚â”€â”€ main.py             # OrquestraÃ§Ã£o do pipeline
â”‚â”€â”€ data_lake/          # Armazenamento dos dados brutos
â”‚   â””â”€â”€ curated/        # Dados curados (ex: mÃ©dias)
â”‚â”€â”€ graficos_output/    # SaÃ­da dos grÃ¡ficos
â”‚â”€â”€ requirements.txt    # DependÃªncias do projeto
```

---

## ğŸ“Œ ObservaÃ§Ãµes
- O pipeline foi estruturado de forma **modular**, permitindo evoluÃ§Ã£o futura (como conexÃ£o com banco de dados, dashboards no Power BI, ou agendamento automÃ¡tico).  
- O objetivo Ã© **simular o fluxo real de um engenheiro/analista de dados**, mas em um escopo didÃ¡tico.  
